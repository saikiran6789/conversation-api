**ğŸ§  AI Conversation API â€” Secure Streaming Chat Backend**

A production-grade AI Conversation REST API built with FastAPI + Supabase + Groq (LLM) featuring:

**ğŸ” JWT Authentication**

**ğŸ’¬ Conversation CRUD**

**âš¡ Real-time SSE streaming (token-by-token)**

**ğŸ“Š Token usage tracking**

**ğŸ›¡ï¸ Row Level Security (RLS)**

**ğŸ“˜ Auto-generated Swagger Docs**

**ğŸ”’ Secure architecture**

**ğŸš€ Tech Stack**
Component	Technology
Framework	FastAPI
Database	Supabase PostgreSQL
Auth	Custom JWT
LLM	Groq (Llama 3.1 8B Instant)
Streaming	Server-Sent Events (SSE)
Validation	Pydantic
Docs	Swagger (/docs)
**ğŸ“‚ Project Structure**
conversation-api/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ auth/
â”‚   â”œâ”€â”€ conversations/
â”‚   â”œâ”€â”€ messages/
â”‚   â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ db/
â”‚   â””â”€â”€ middleware/
â”‚
â”œâ”€â”€ database/schema.sql
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

**âš™ï¸ Setup Instructions**
**1ï¸âƒ£ Clone the repository**
git clone https://github.com/saikiran6789/conversation-api
cd conversation-api

**2ï¸âƒ£ Create virtual environment**
python -m venv venv
venv\Scripts\activate   # Windows

**3ï¸âƒ£ Install dependencies**
pip install -r requirements.txt

**4ï¸âƒ£ Setup Environment Variables**

Create .env file:

JWT_SECRET=your_secure_secret
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

GROQ_API_KEY=your_groq_api_key

**5ï¸âƒ£ Run the server**
uvicorn main:app --reload --app-dir src


Server runs at:

http://127.0.0.1:8000


Swagger Docs:

http://127.0.0.1:8000/docs

**ğŸ” Authentication Flow**
Register

POST /api/v1/auth/register

Returns:

{
  "access_token": "..."
}

Login

POST /api/v1/auth/login

Returns new JWT token.

Use token in:

Authorization: Bearer <token>

**ğŸ’¬ Conversations**
Create Conversation

POST /api/v1/conversations

Returns:

{
  "id": "uuid-value"
}

List Conversations

GET /api/v1/conversations

**âš¡ Streaming Messages**
Stream Endpoint
POST /api/v1/conversations/{conversation_id}/messages/stream


Streaming format follows SSE standard:

event: message_start
event: content_block_delta
event: message_delta
event: message_stop


âœ” Token-by-token streaming
âœ” Proper SSE format
âœ” Error event handling
âœ” Latency tracking
âœ” Usage tracking

**ğŸ“Š Token & Usage Tracking**

Each assistant message stores:

token_count

finish_reason

latency_ms

model

metadata

**ğŸ›¡ï¸ Security Features**

âœ… JWT Authentication

âœ… Supabase Row Level Security

âœ… Authorization (users access only their data)

âœ… Input validation (Pydantic)

âœ… Secure password hashing (bcrypt)

âœ… Environment variable secrets

âœ… Structured error responses

ğŸ—„ï¸ Database Schema

**Tables:**

users

conversations

messages

api_keys (optional)

See: database/schema.sql

**ğŸ“¡ Streaming Implementation**


Real-time token delivery

Proper SSE event format

Graceful error handling

Message persisted after stream completion

Token usage stored

Finish reason tracked
